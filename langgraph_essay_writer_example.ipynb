{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essay Writer Agent Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "# Set up memory\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to keep track of all elements in a state\n",
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: List[str]\n",
    "    revision_number: int\n",
    "    max_revisions: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "model = OllamaLLM(model=\"qwen2.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAN_PROMPT = \"\"\"You are an expert writer tasked with writing a high level outline of an essay. \\\n",
    "Write such an outline for the user provided topic. Give an outline of the essay along with any relevant notes \\\n",
    "or instructions for the sections.\"\"\"\n",
    "\n",
    "WRITER_PROMPT = \"\"\"You are an essay assistant tasked with writing excellent 5-paragraph essays.\\\n",
    "Generate the best essay possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of your previous attempts. \\\n",
    "Utilize all the information below as needed: \n",
    "\n",
    "------\n",
    "\n",
    "{content}\"\"\"\n",
    "\n",
    "REFLECTION_PROMPT = \"\"\"You are a teacher grading an essay submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\"\"\"\n",
    "\n",
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when writing the following essay. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate 3 queries max.\"\"\"\n",
    "\n",
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as outlined below). \\\n",
    "Generate a list of search queries that will gather any relevant information. Only generate 3 queries max.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[str]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Nodes\n",
    "\n",
    "- Planning\n",
    "- Research\n",
    "- Generation\n",
    "- Reflection\n",
    "- Critique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT), \n",
    "        HumanMessage(content=state['task'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"plan\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_plan_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "        HumanMessage(content=state['task'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        # search() returns a string\n",
    "        response_string = search(query=q) # Removed max_results, handle if needed via tool config\n",
    "        if response_string: # Append if not empty\n",
    "             content.append(response_string)\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation_node(state: AgentState):\n",
    "    content = \"\\n\\n\".join(state['content'] or [])\n",
    "    user_message = HumanMessage(\n",
    "        content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\")\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=WRITER_PROMPT.format(content=content)\n",
    "        ),\n",
    "        user_message\n",
    "        ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\n",
    "        \"draft\": response, \n",
    "        \"revision_number\": state.get(\"revision_number\", 1) + 1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT), \n",
    "        HumanMessage(content=state['draft'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"critique\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_critique_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "        HumanMessage(content=state['critique'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        # search() returns a string\n",
    "        response_string = search(query=q) # Removed max_results, handle if needed via tool config\n",
    "        if response_string: # Append if not empty\n",
    "             content.append(response_string)\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        return END\n",
    "    return \"reflect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x29b144bd220>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_node(\"planner\", plan_node)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "builder.add_node(\"research_plan\", research_plan_node)\n",
    "builder.add_node(\"research_critique\", research_critique_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x29b144bd220>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.set_entry_point(\"planner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x29b144bd220>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_conditional_edges(\n",
    "    \"generate\", \n",
    "    should_continue, \n",
    "    {END: END, \"reflect\": \"reflect\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x29b144bd220>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_edge(\"planner\", \"research_plan\")\n",
    "builder.add_edge(\"research_plan\", \"generate\")\n",
    "\n",
    "builder.add_edge(\"reflect\", \"research_critique\")\n",
    "builder.add_edge(\"research_critique\", \"generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image\n",
    "\n",
    "# Image(graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling graph with checkpointer...\n",
      "Graph compiled.\n",
      "Streaming graph for thread: 1\n",
      "---\n",
      "{'planner': {'plan': '### Essay Outline: Understanding the Difference Between LangChain and LangSmith\\n\\n#### Introduction\\n- **Background Information:** Briefly introduce both platforms (LangChain, LangSmith) in the context of natural language processing and artificial intelligence tools.\\n- **Thesis Statement:** State that while both are part of the larger ecosystem of AI development frameworks, they serve different purposes and have distinct features.\\n\\n#### Section 1: Overview of LangChain\\n- **Definition and Purpose:** Define what LangChain is and its primary purpose in the AI landscape.\\n    - Note: Emphasize its role as an open-source library for building powerful LLM (Large Language Model) applications.\\n- **Key Features:** Highlight key features such as ease of integration, modular architecture, and community support.\\n- **Use Cases:** Provide examples or case studies where LangChain has been effectively utilized.\\n\\n#### Section 2: Overview of LangSmith\\n- **Definition and Purpose:** Define what LangSmith is and its primary purpose in the AI landscape.\\n    - Note: Explain that it focuses on streamlining the development process, particularly for LLM applications, with a focus on developer tools and workflows.\\n- **Key Features:** Discuss key features such as debugging tools, version control, and seamless deployment options.\\n- **Use Cases:** Provide examples or case studies where LangSmith has been effectively utilized.\\n\\n#### Section 3: Comparison of Key Differences\\n- **Development Focus:** Compare the development approach of both platforms. Note that LangChain is more about providing a building block for developers to construct applications using LLMs, whereas LangSmith provides comprehensive tools and services to make this process smoother.\\n- **Integration Capabilities:** Discuss how each platform integrates with different LLMs and other AI technologies. Highlight any unique integration capabilities of one over the other.\\n- **Community Support and Ecosystem:** Compare community support and ecosystem availability. Note that open-source projects like LangChain often have a strong developer community, while proprietary tools like LangSmith may offer more specialized support and resources.\\n\\n#### Section 4: Conclusion\\n- **Summary of Key Points:** Recap the main differences between LangChain and LangSmith.\\n- **Reiteration of Thesis Statement:** Reiterate the importance of understanding these differences in choosing the right tool for a specific project or task.\\n- **Recommendations:** Offer recommendations based on different needs, such as open-source projects versus proprietary tools.\\n\\n#### Notes:\\n- **Research Thoroughly:** Ensure you have up-to-date information about both platforms by referring to official documentation and user testimonials.\\n- **Contextual Examples:** Use real-world examples where possible to illustrate the effectiveness of each platform in specific scenarios.\\n- **Technical Accuracy:** Make sure that technical terms are clearly defined, especially for readers who might not be familiar with LLMs or AI development tools.\\n\\nThis outline should provide a comprehensive framework for comparing LangChain and LangSmith, helping readers understand their unique features and applications.'}}\n",
      "\n",
      "Error during stream: \n",
      "--- Stream finished ---\n"
     ]
    }
   ],
   "source": [
    "memory_context = SqliteSaver.from_conn_string(\":memory:\")\n",
    "\n",
    "with memory_context as checkpointer:  # Use the newly created context manager\n",
    "    # Compile the graph inside the 'with' block\n",
    "    print(\"Compiling graph with checkpointer...\")\n",
    "    graph = builder.compile(checkpointer=checkpointer)\n",
    "    print(\"Graph compiled.\")\n",
    "\n",
    "    # Also run the stream inside the 'with' block\n",
    "    thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "    print(f\"Streaming graph for thread: {thread['configurable']['thread_id']}\")\n",
    "    try:\n",
    "        for s in graph.stream({\n",
    "            'task': \"what is the difference between langchain and langsmith\",\n",
    "            \"max_revisions\": 2,\n",
    "            \"revision_number\": 1, # Start with revision 1\n",
    "        }, thread):\n",
    "            print(\"---\")\n",
    "            print(s)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during stream: {e}\") # Add error handling for clarity\n",
    "    finally:\n",
    "        print(\"--- Stream finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from helper import ewriter, writer_gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiAgent = ewriter()\n",
    "# app = writer_gui(MultiAgent.graph)\n",
    "# app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-agent-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
